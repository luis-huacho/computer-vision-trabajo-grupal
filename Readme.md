# U-Net Autoencoder para RemociÃ³n de Fondo

Un modelo de deep learning avanzado que utiliza arquitectura U-Net con Attention Gates para remover automÃ¡ticamente el fondo de imÃ¡genes, manteniendo Ãºnicamente las personas detectadas.

## ğŸ¯ CaracterÃ­sticas Principales

- **Arquitectura HÃ­brida**: Combina U-Net con Autoencoder para segmentaciÃ³n y reconstrucciÃ³n de alta calidad
- **Attention Mechanisms**: Implementa Attention Gates para enfocarse en regiones de personas
- **Transfer Learning**: Utiliza ResNet34 pre-entrenado como backbone del encoder
- **MÃºltiples Funciones de PÃ©rdida**: Combina BCE, Dice, Perceptual y Edge Loss para resultados superiores
- **Sistema de Checkpoints**: Guarda automÃ¡ticamente las mejores versiones del modelo
- **Logging Completo**: Registro detallado del proceso de entrenamiento
- **MÃ©tricas Avanzadas**: IoU, Dice Coefficient, Pixel Accuracy y mÃ¡s

## ğŸ—ï¸ Arquitectura del Modelo

### Encoder Path (Downsampling)
```
Input (256x256x3) â†’ ResNet34 Backbone â†’ Bottleneck (16x16x1024)
                                     â†“
Skip Connections: [64, 64, 128, 256, 512] channels
```

### Decoder Path (Upsampling)
```
Bottleneck â†’ Attention Gates + Skip Connections â†’ Output (256x256x4)
           â†“
RGBA Output: RGB channels + Alpha mask
```

### Componentes Clave
- **Attention Blocks**: Enfocan el modelo en regiones relevantes
- **Double Convolution**: Bloques conv-bn-relu-conv-bn-relu
- **Skip Connections**: Preservan detalles de alta resoluciÃ³n
- **Multi-Scale Loss**: Optimiza a diferentes niveles de resoluciÃ³n

## ğŸ“‹ Requisitos

### Dependencias Principales
```bash
torch>=1.9.0
torchvision>=0.10.0
opencv-python>=4.5.0
albumentations>=1.0.0
numpy>=1.21.0
matplotlib>=3.4.0
Pillow>=8.3.0
scikit-learn>=0.24.0
```

### Hardware Recomendado
- **GPU**: NVIDIA GTX 1080 Ti o superior (8GB+ VRAM)
- **RAM**: 16GB+ para procesamiento de datasets grandes
- **Almacenamiento**: 20GB+ para dataset y checkpoints

## ğŸš€ InstalaciÃ³n

1. **Clonar el repositorio**
```bash
git clone https://github.com/tu-usuario/unet-background-removal.git
cd unet-background-removal
```

2. **Crear entorno virtual**
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# o
venv\Scripts\activate  # Windows
```

3. **Instalar dependencias**
```bash
pip install -r requirements.txt
```

4. **Descargar dataset Supervisely Persons**
```bash
# Descargar desde: https://github.com/supervisely-ecosystem/persons
# Extraer en: data/supervisely_persons/
```

## ğŸ“ Estructura del Proyecto

```
unet-background-removal/
â”œâ”€â”€ main.py                 # Modelo principal y entrenamiento
â”œâ”€â”€ README.md              # Este archivo
â”œâ”€â”€ concepts.md            # Conceptos tÃ©cnicos y mÃ©tricas
â”œâ”€â”€ requirements.txt       # Dependencias
â”œâ”€â”€ data/
â”‚   â””â”€â”€ supervisely_persons/
â”‚       â”œâ”€â”€ images/        # ImÃ¡genes originales
â”‚       â””â”€â”€ annotations/   # Anotaciones JSON
â”œâ”€â”€ checkpoints/           # Modelos guardados
â”‚   â”œâ”€â”€ best_model.pth    # Mejor modelo
â”‚   â””â”€â”€ last_model.pth    # Ãšltimo checkpoint
â”œâ”€â”€ logs/                 # Logs de entrenamiento
â”œâ”€â”€ plots/               # GrÃ¡ficas de entrenamiento
â””â”€â”€ output/             # Resultados de inferencia
```

## ğŸ“ Uso

### Entrenamiento

```python
# Configurar parÃ¡metros
config = {
    'batch_size': 8,
    'learning_rate': 1e-4,
    'num_epochs': 100,
    'image_size': 256
}

# Ejecutar entrenamiento
python main.py
```

### Inferencia

```python
from main import ModelInference

# Cargar modelo entrenado
inference = ModelInference('checkpoints/best_model.pth')

# Remover fondo de una imagen
result = inference.remove_background('input.jpg', 'output.png')

# Procesamiento en lote
inference.batch_process('input_dir/', 'output_dir/')
```

## ğŸ“Š MÃ©tricas de EvaluaciÃ³n

### MÃ©tricas de SegmentaciÃ³n
- **IoU (Intersection over Union)**: Mide la superposiciÃ³n entre predicciÃ³n y ground truth
- **Dice Coefficient**: Similitud entre mÃ¡scaras binarias
- **Pixel Accuracy**: PrecisiÃ³n a nivel de pixel

### MÃ©tricas de Calidad Visual
- **BCE Loss**: Binary Cross Entropy para clasificaciÃ³n
- **Perceptual Loss**: Preserva caracterÃ­sticas visuales naturales
- **Edge Loss**: Mantiene contornos nÃ­tidos

## ğŸ”§ ConfiguraciÃ³n Avanzada

### ParÃ¡metros del Modelo
```python
model = UNetAutoencoder(
    pretrained=True,      # Usar ResNet pre-entrenado
    use_attention=True    # Activar Attention Gates
)
```

### Funciones de PÃ©rdida
```python
loss_weights = {
    'alpha': 1.0,    # BCE Loss weight
    'beta': 1.0,     # Dice Loss weight
    'gamma': 0.5,    # Perceptual Loss weight
    'delta': 0.3     # Edge Loss weight
}
```

### AumentaciÃ³n de Datos
```python
transforms = [
    HorizontalFlip(p=0.5),
    RandomRotate90(p=0.3),
    ShiftScaleRotate(p=0.5),
    RandomBrightnessContrast(p=0.5),
    HueSaturationValue(p=0.3),
    GaussianBlur(p=0.2)
]
```

## ğŸ“ˆ Resultados Esperados

### MÃ©tricas Objetivo
- **IoU**: > 0.85 en validaciÃ³n
- **Dice Coefficient**: > 0.90 en validaciÃ³n
- **Pixel Accuracy**: > 0.95 en validaciÃ³n

### Tiempo de Entrenamiento
- **100 Ã©pocas**: ~4-6 horas en RTX 3080
- **Convergencia**: TÃ­picamente en 50-70 Ã©pocas
- **Inferencia**: ~50ms por imagen (256x256)

## ğŸ› ï¸ SoluciÃ³n de Problemas

### Error de Memoria GPU
```python
# Reducir batch size
config['batch_size'] = 4

# Usar gradient checkpointing
torch.utils.checkpoint.checkpoint()
```

### Dataset No Encontrado
```bash
# Verificar estructura de directorios
ls data/supervisely_persons/images/
ls data/supervisely_persons/annotations/
```

### Problemas de Convergencia
```python
# Ajustar learning rate
config['learning_rate'] = 5e-5

# Usar scheduler mÃ¡s agresivo
scheduler = CosineAnnealingLR(optimizer, T_max=50)
```

## ğŸ“š Referencias y Recursos

### Papers Clave
- [U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/abs/1505.04597)
- [Attention U-Net: Learning Where to Look for the Pancreas](https://arxiv.org/abs/1804.03999)
- [ResNet: Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)

### Dataset
- [Supervisely Persons Dataset](https://github.com/supervisely-ecosystem/persons)
- [Dataset Ninja - Supervisely Persons](https://datasetninja.com/supervisely-persons)

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Por favor:

1. Fork el repositorio
2. Crea una rama para tu feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit tus cambios (`git commit -am 'AÃ±adir nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Crea un Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver `LICENSE` para mÃ¡s detalles.

## ğŸ™ Agradecimientos

- **Supervisely Team** por el dataset de alta calidad
- **PyTorch Team** por el framework de deep learning
- **Albumentations** por las herramientas de augmentaciÃ³n
- **OpenCV Community** por las utilidades de procesamiento de imÃ¡genes

## ğŸ“ Contacto

Para preguntas, sugerencias o colaboraciones:

- **Email**: tu-email@ejemplo.com
- **GitHub**: [@tu-usuario](https://github.com/tu-usuario)
- **LinkedIn**: [Tu Perfil](https://linkedin.com/in/tu-perfil)

---

**Â¿Encontraste este proyecto Ãºtil? Â¡Dale una â­ en GitHub!**