# Configuraciones de Entrenamiento - Archivos YAML

Sistema de configuraci√≥n flexible para experimentos de deep learning en segmentaci√≥n de personas.

**Proyecto**: U-Net Background Removal with Harmonization
**Autores**: Luis Huacho y Dominick Alvarez - PUCP

---

## üìÅ Archivos de Configuraci√≥n Disponibles

### 1. `default.yaml`
**Configuraci√≥n est√°ndar de producci√≥n**

- **Arquitectura**: ResNet-50
- **Dataset**: COCO completo (sin muestreo)
- **Epochs**: 100
- **Batch Size**: 16
- **Workers**: 8
- **Uso**: Entrenamiento completo y robusto

```bash
python main.py train  # Usa default.yaml autom√°ticamente
```

---

### 2. `resnet50_full.yaml`
**ResNet-50 con todas las caracter√≠sticas**

- **Arquitectura**: ResNet-50
- **Dataset**: COCO completo
- **Epochs**: 100
- **Caracter√≠sticas**: Mixed precision, attention gates, scheduler cosine annealing
- **Uso**: Entrenamiento de producci√≥n optimizado

```bash
python main.py train --config resnet50_full
```

---

### 3. `resnet34_quick.yaml`
**Prueba r√°pida con ResNet-34 y subset**

- **Arquitectura**: ResNet-34 (m√°s ligero)
- **Dataset**: **Subset de 1000 im√°genes**
- **Epochs**: 20
- **Batch Size**: 16
- **Uso**: Iteraci√≥n r√°pida, experimentaci√≥n, validaci√≥n de pipeline

```bash
python main.py train --config resnet34_quick
```

**Ideal para**:
- ‚úÖ Probar cambios en el c√≥digo
- ‚úÖ Validar que el pipeline funciona
- ‚úÖ Experimentar con hiperpar√°metros
- ‚úÖ Debugging

---

### 4. `resnet50_10percent.yaml`
**10% del dataset para validaci√≥n intermedia**

- **Arquitectura**: ResNet-50
- **Dataset**: 10% del COCO (muestreo aleatorio)
- **Epochs**: 30
- **Batch Size**: 16
- **Uso**: Punto medio entre quick y full

```bash
python main.py train --config resnet50_10percent
```

**Ideal para**:
- ‚úÖ Validar hiperpar√°metros antes de full training
- ‚úÖ Comparar configuraciones sin esperar 100 epochs
- ‚úÖ Obtener m√©tricas representativas r√°pidamente

---

### 5. `debug.yaml`
**Configuraci√≥n m√≠nima para debugging**

- **Arquitectura**: ResNet-34
- **Dataset**: **Solo 100 im√°genes**
- **Epochs**: 3
- **Batch Size**: 4
- **Workers**: 2
- **Mixed Precision**: Desactivado
- **Uso**: Verificar errores, debugging, desarrollo

```bash
python main.py train --config debug
```

**Ideal para**:
- ‚úÖ Verificar que el c√≥digo no tiene errores
- ‚úÖ Probar nuevas features
- ‚úÖ Debugging paso a paso
- ‚úÖ CI/CD testing

---

## üÜï Configs para AISegment Dataset

### 6. `aisegment_full.yaml`
**Dataset AISegment completo - ResNet-50**

- **Arquitectura**: ResNet-50
- **Dataset**: AISegment completo (34,425 im√°genes)
- **Epochs**: 100
- **Batch Size**: 16
- **Descarga**: Autom√°tica con kagglehub
- **Uso**: Entrenamiento de producci√≥n con matting de alta calidad

```bash
python main.py train --config aisegment_full
```

**Caracter√≠sticas**:
- ‚úÖ Descarga autom√°tica del dataset desde Kaggle
- ‚úÖ Matting profesional con canal alpha suave
- ‚úÖ 34,425 retratos de medio cuerpo de alta calidad
- ‚úÖ Configuraci√≥n optimizada para producci√≥n

**Prerequisito**: API key de Kaggle configurada (ver `docs/AISegment_Setup.md`)

---

### 7. `aisegment_10percent.yaml`
**10% del AISegment para validaci√≥n intermedia**

- **Arquitectura**: ResNet-50
- **Dataset**: ~3,400 im√°genes (10% de AISegment)
- **Epochs**: 50
- **Batch Size**: 16
- **Uso**: Validaci√≥n de hiperpar√°metros

```bash
python main.py train --config aisegment_10percent
```

**Ideal para**:
- ‚úÖ Probar configuraciones antes de full training
- ‚úÖ Validar cambios en el modelo
- ‚úÖ Experimentaci√≥n r√°pida con dataset real

---

### 8. `aisegment_quick.yaml`
**Prueba r√°pida con 1000 im√°genes - ResNet-34**

- **Arquitectura**: ResNet-34 (m√°s ligero)
- **Dataset**: 1,000 im√°genes de AISegment
- **Epochs**: 20
- **Batch Size**: 16
- **Uso**: Iteraci√≥n r√°pida y experimentaci√≥n

```bash
python main.py train --config aisegment_quick
```

**Ideal para**:
- ‚úÖ Validar pipeline con AISegment
- ‚úÖ Pruebas r√°pidas (~20 minutos)
- ‚úÖ Experimentar con matting de retratos
- ‚úÖ Comparar con COCO

---

## üöÄ Uso R√°pido

### Opci√≥n 1: Config por defecto
```bash
python main.py train
```
Carga autom√°ticamente `configs/default.yaml`

### Opci√≥n 2: Config por nombre
```bash
python main.py train --config resnet50_full
python main.py train --config resnet34_quick
python main.py train --config debug
```
Busca el archivo en `configs/{nombre}.yaml`

### Opci√≥n 3: Path completo
```bash
python main.py train --config-path /ruta/completa/mi_config.yaml
python main.py train --config-path configs/experimento_custom.yaml
```

### Listar configuraciones disponibles
```bash
python main.py help
```

---

## üìù Estructura de un Archivo YAML

### Secciones Principales

```yaml
# ============================================================================
# 1. INFORMACI√ìN DEL EXPERIMENTO
# ============================================================================
experiment:
  name: "Nombre del Experimento"
  description: "Descripci√≥n detallada"
  mode: "production"  # production, debug, quick_test

# ============================================================================
# 2. CONFIGURACI√ìN DEL MODELO
# ============================================================================
model:
  architecture: "resnet50"  # resnet50 o resnet34
  image_size: 384
  use_pretrained: true      # Usar pesos pre-entrenados ImageNet
  use_attention: true       # Attention gates en decoder

# ============================================================================
# 3. CONFIGURACI√ìN DEL DATASET
# ============================================================================
dataset:
  type: "coco"              # coco o supervisely
  root: "COCO"              # Directorio del dataset

  # Filtros de calidad
  min_person_area: 500      # √Årea m√≠nima en p√≠xeles
  min_keypoints: 3          # M√≠nimo de keypoints visibles
  train_val_split: 0.8      # 80% train, 20% val

  # MUESTREO/SUBSET (para experimentos r√°pidos)
  sampling:
    enabled: false          # Activar o desactivar
    mode: "full"            # full, subset, percentage
    subset_size: null       # N√∫mero de im√°genes (si mode=subset)
    percentage: null        # Porcentaje 0-1 (si mode=percentage)
    strategy: "random"      # random, first, balanced
    random_seed: 42         # Para reproducibilidad

# ============================================================================
# 4. CONFIGURACI√ìN DE ENTRENAMIENTO
# ============================================================================
training:
  # Hiperpar√°metros b√°sicos
  num_epochs: 100
  batch_size: 16
  learning_rate: 0.0001
  weight_decay: 0.000001

  # DataLoader
  num_workers: 8
  pin_memory: true
  drop_last: true

  # Optimizaci√≥n
  gradient_clip_max_norm: 0.5
  mixed_precision: true

  # Learning Rate Scheduler
  scheduler:
    type: "cosine_annealing"  # cosine_annealing, step, plateau
    T_0: 10                    # Para cosine_annealing
    T_mult: 2
    # O para step scheduler:
    # step_size: 30
    # gamma: 0.1

  # Pesos de las funciones de p√©rdida
  loss_weights:
    alpha: 1.0   # BCE (Binary Cross Entropy)
    beta: 1.0    # Dice Loss
    gamma: 0.5   # Perceptual Loss (VGG)
    delta: 0.3   # Edge Loss

# ============================================================================
# 5. CONFIGURACI√ìN DE VALIDACI√ìN
# ============================================================================
validation:
  frequency: 1              # Validar cada N √©pocas

  early_stopping:
    enabled: true
    patience: 15            # √âpocas sin mejora antes de parar
    min_delta: 0.0001       # Mejora m√≠nima considerada

  # M√©tricas objetivo
  target_metrics:
    iou: 0.85
    dice: 0.90
    pixel_accuracy: 0.95

# ============================================================================
# 6. CONFIGURACI√ìN DE CHECKPOINTS Y LOGGING
# ============================================================================
checkpoints:
  save_best: true
  save_last: true
  save_every_n_epochs: 5
  checkpoint_dir: "checkpoints/resnet50"

logging:
  log_every_n_batches: 10
  save_plots: true
  plot_dpi: 300

# ============================================================================
# 7. AUMENTACI√ìN DE DATOS
# ============================================================================
augmentation:
  train:
    horizontal_flip: 0.5
    random_rotate90: 0.3
    shift_scale_rotate:
      enabled: true
      shift_limit: 0.1
      scale_limit: 0.2
      rotate_limit: 15
      p: 0.5
    brightness_contrast:
      enabled: true
      brightness_limit: 0.2
      contrast_limit: 0.2
      p: 0.5
```

---

## üéØ Casos de Uso Comunes

### Caso 1: Experimentar con Hiperpar√°metros

**Problema**: Quiero probar diferentes learning rates sin esperar 100 epochs

**Soluci√≥n**: Crear config con subset y menos epochs

```yaml
# configs/lr_experiment.yaml
experiment:
  name: "LR Experiment - 5e-5"

model:
  architecture: "resnet34"  # M√°s r√°pido

dataset:
  sampling:
    enabled: true
    mode: "percentage"
    percentage: 0.1  # Solo 10% del dataset

training:
  num_epochs: 20
  learning_rate: 0.00005  # Probar nuevo LR
```

```bash
python main.py train --config lr_experiment
```

---

### Caso 2: Comparar Arquitecturas

**Problema**: ¬øResNet-50 o ResNet-34 es mejor para mi caso?

**Soluci√≥n**: Crear dos configs y comparar

```yaml
# configs/compare_resnet50.yaml
experiment:
  name: "Compare - ResNet50"
model:
  architecture: "resnet50"
dataset:
  sampling:
    enabled: true
    mode: "subset"
    subset_size: 5000
training:
  num_epochs: 30
checkpoints:
  checkpoint_dir: "checkpoints/compare_resnet50"
```

```yaml
# configs/compare_resnet34.yaml
experiment:
  name: "Compare - ResNet34"
model:
  architecture: "resnet34"
dataset:
  sampling:
    enabled: true
    mode: "subset"
    subset_size: 5000
training:
  num_epochs: 30
checkpoints:
  checkpoint_dir: "checkpoints/compare_resnet34"
```

```bash
python main.py train --config compare_resnet50
python main.py train --config compare_resnet34
# Comparar m√©tricas en logs/
```

---

### Caso 3: Entrenamiento Completo de Producci√≥n

**Problema**: Configuraci√≥n final para paper/producci√≥n

**Soluci√≥n**: Usar config de producci√≥n con dataset completo

```bash
# Opci√≥n 1: Usar resnet50_full.yaml
python main.py train --config resnet50_full

# Opci√≥n 2: Crear config personalizado
cp configs/resnet50_full.yaml configs/production_final.yaml
# Editar production_final.yaml seg√∫n necesidades
python main.py train --config production_final
```

---

### Caso 4: Debugging de Errores

**Problema**: Mi c√≥digo falla y no s√© d√≥nde

**Soluci√≥n**: Usar debug.yaml con datos m√≠nimos

```bash
python main.py train --config debug
# Si falla, el error aparece r√°pido (3 epochs, 100 im√°genes)
# Si funciona, escalar a resnet34_quick.yaml
```

---

## üìä Muestreo/Subset de Datos

### ¬øPor qu√© usar muestreo?

- ‚ö° **Iteraci√≥n r√°pida**: Probar cambios sin esperar horas
- üí∞ **Ahorro de recursos**: GPU/CPU/tiempo
- üî¨ **Experimentaci√≥n**: Probar m√∫ltiples configuraciones
- üêõ **Debugging**: Encontrar errores r√°pidamente

### Modos de Muestreo

#### 1. `mode: "full"` - Dataset Completo
```yaml
sampling:
  enabled: false  # O enabled: true con mode: "full"
  mode: "full"
```
Usa todas las im√°genes disponibles.

#### 2. `mode: "subset"` - Cantidad Fija
```yaml
sampling:
  enabled: true
  mode: "subset"
  subset_size: 1000  # Exactamente 1000 im√°genes
  strategy: "random"  # Aleatorio
  random_seed: 42
```
Especifica n√∫mero exacto de im√°genes.

#### 3. `mode: "percentage"` - Porcentaje
```yaml
sampling:
  enabled: true
  mode: "percentage"
  percentage: 0.1  # 10% del dataset
  strategy: "random"
```
√ötil cuando no sabes el tama√±o total del dataset.

### Estrategias de Muestreo

- **`"random"`**: Selecci√≥n aleatoria (recomendado)
- **`"first"`**: Primeras N im√°genes (m√°s r√°pido, menos representativo)
- **`"balanced"`**: Balanceo por clases (futuro)

---

## üõ†Ô∏è Crear Tu Propia Configuraci√≥n

### Paso 1: Copiar Template
```bash
cp configs/default.yaml configs/mi_experimento.yaml
```

### Paso 2: Editar Seg√∫n Necesidades
```yaml
experiment:
  name: "Mi Experimento - Loss Weights"
  description: "Probando diferentes pesos de p√©rdidas"

model:
  architecture: "resnet50"

dataset:
  sampling:
    enabled: true
    mode: "subset"
    subset_size: 2000  # Dataset reducido para pruebas

training:
  num_epochs: 40
  batch_size: 16

  # Modificar pesos de p√©rdidas
  loss_weights:
    alpha: 1.0
    beta: 2.0    # Aumentar peso de Dice
    gamma: 0.3   # Reducir perceptual
    delta: 0.5   # Aumentar edge

checkpoints:
  checkpoint_dir: "checkpoints/loss_experiment"
```

### Paso 3: Ejecutar
```bash
python main.py train --config mi_experimento
```

### Paso 4: Versionar
```bash
git add configs/mi_experimento.yaml
git commit -m "Add mi_experimento config"
```

---

## üìñ Referencia R√°pida

### Par√°metros Comunes

| Par√°metro | Valores | Descripci√≥n |
|-----------|---------|-------------|
| `architecture` | `resnet50`, `resnet34` | Backbone del U-Net |
| `image_size` | `256`, `384`, `512` | Tama√±o de entrada |
| `batch_size` | `4`, `8`, `16`, `32` | Depende de VRAM |
| `learning_rate` | `1e-4`, `5e-5`, `1e-3` | Ajustar seg√∫n necesidad |
| `num_epochs` | `20`, `50`, `100` | Balance tiempo/calidad |
| `num_workers` | `0`, `4`, `8`, `16` | Depende de CPU |
| `mixed_precision` | `true`, `false` | Ahorra VRAM, m√°s r√°pido |

### Scheduler Types

| Type | Uso | Par√°metros |
|------|-----|------------|
| `cosine_annealing` | General (recomendado) | `T_0`, `T_mult` |
| `step` | Decaimiento por steps | `step_size`, `gamma` |
| `plateau` | Adaptativo por m√©trica | `patience`, `factor` |

### Sampling Modes

| Mode | Cu√°ndo Usar | Par√°metro |
|------|-------------|-----------|
| `full` | Producci√≥n, training final | - |
| `subset` | Conoces dataset, quieres N im√°genes | `subset_size` |
| `percentage` | Dataset variable, quieres X% | `percentage` |

---

## ‚ö†Ô∏è Advertencias y Tips

### ‚úÖ Buenas Pr√°cticas

1. **Nombra descriptivamente**: `resnet50_lr5e5_bs32.yaml` mejor que `config1.yaml`
2. **Versionina configs**: Agregar a git para reproducibilidad
3. **Documenta cambios**: Usa `description` en el YAML
4. **Empieza peque√±o**: Usa `debug` o `quick` antes de `full`
5. **Guarda m√©tricas**: Checkpoints separados por experimento

### ‚ùå Errores Comunes

1. **Batch size muy grande**: OOM error
   - Soluci√≥n: Reducir `batch_size` o activar `mixed_precision`

2. **Num workers muy alto**: Congela o ralentiza
   - Soluci√≥n: `num_workers` = n√∫mero de CPU cores / 2

3. **Dataset no existe**: FileNotFoundError
   - Soluci√≥n: Verificar `dataset.root` apunta al directorio correcto

4. **Config no encontrado**: FileNotFoundError
   - Soluci√≥n: Verificar que archivo existe en `configs/`
   - Usar `python main.py help` para listar disponibles

---

## üîó Referencias

- **Documentaci√≥n completa**: Ver `CLAUDE.md` en ra√≠z del proyecto
- **C√≥digo**: `config_loader.py`, `trainer.py`, `main.py`
- **Datasets**: `Readme.COCO.md` para setup de COCO

---

## üìû Soporte

**Proyecto**: U-Net Background Removal with Harmonization
**Autores**: Luis Huacho y Dominick Alvarez
**Instituci√≥n**: Maestr√≠a en Inform√°tica, PUCP

Para m√°s informaci√≥n, consultar la documentaci√≥n completa en `CLAUDE.md` y `Readme.md`.
