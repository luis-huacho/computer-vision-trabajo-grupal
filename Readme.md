# U-Net Autoencoder para Remoci√≥n de Fondo

Un modelo de deep learning que utiliza arquitectura U-Net con Attention Gates para remover autom√°ticamente el fondo de im√°genes, manteniendo √∫nicamente las personas detectadas.

**Desarrollado por:** Luis Huacho y Dominick Alvarez  
**Instituci√≥n:** Maestr√≠a en Inform√°tica, PUCP

## üéØ Caracter√≠sticas Principales

- **Arquitectura H√≠brida**: U-Net con Autoencoder para segmentaci√≥n y reconstrucci√≥n
- **Attention Gates**: Enfoque autom√°tico en regiones de personas
- **Transfer Learning**: ResNet34 pre-entrenado como backbone
- **M√∫ltiples Funciones de P√©rdida**: BCE, Dice, Perceptual y Edge Loss
- **Preservaci√≥n de Dimensiones**: Mantiene el tama√±o original de la imagen

## üèóÔ∏è Arquitectura del Modelo

```
Input (RGB) ‚Üí ResNet34 Encoder ‚Üí Bottleneck ‚Üí Attention Decoder ‚Üí Output (RGBA)
             ‚Üì                                ‚Üë
        Skip Connections ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Componentes Clave
- **UNetEncoder**: ResNet34 con skip connections [64, 64, 128, 256, 512] canales
- **UNetDecoder**: Upsampling con Attention Gates
- **ImageProcessor**: Redimensionamiento con padding que preserva proporciones
- **LossCalculator**: P√©rdida compuesta optimizada para segmentaci√≥n

## üìã Requisitos

```
torch>=1.9.0
torchvision>=0.10.0
opencv-python>=4.5.0
albumentations>=1.0.0
numpy>=1.21.0
matplotlib>=3.4.0
streamlit>=1.25.0
scikit-learn>=0.24.0
Pillow>=8.3.0
```

## üöÄ Instalaci√≥n y Uso

### 1. Configuraci√≥n del Entorno

```bash
# Clonar repositorio
git clone <repository-url>
cd unet-background-removal

# Crear entorno virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# Instalar dependencias
pip install -r requirements.txt
```

### 2. Preparar Dataset

Descargar el dataset Supervisely Persons y estructurarlo:

```
persons/
‚îî‚îÄ‚îÄ project/
    ‚îú‚îÄ‚îÄ ds1/
    ‚îÇ   ‚îú‚îÄ‚îÄ img/       # Im√°genes originales
    ‚îÇ   ‚îî‚îÄ‚îÄ ann/       # Anotaciones JSON
    ‚îú‚îÄ‚îÄ ds2/
    ‚îî‚îÄ‚îÄ ...
```

### 3. Entrenamiento

#### Opci√≥n A: Script de Entrenamiento (Recomendado)

```bash
# Entrenamiento normal con logs en archivo
python run_training.py

# Entrenamiento con logs en tiempo real
python run_training.py --verbose

# Sin colores en la salida
python run_training.py --no-color
```

#### Opci√≥n B: Entrenamiento Directo

```bash
# Ejecutar directamente el c√≥digo principal
python main.py
```

### 4. Aplicaci√≥n Web

```bash
# Ejecutar interfaz de Streamlit
streamlit run app.py
```

## üìÅ Estructura del Proyecto

```
unet-background-removal/
‚îú‚îÄ‚îÄ main.py                # Modelo principal y entrenamiento
‚îú‚îÄ‚îÄ run_training.py        # Script automatizado de entrenamiento
‚îú‚îÄ‚îÄ app.py                 # Aplicaci√≥n Streamlit
‚îú‚îÄ‚îÄ README.md             # Este archivo
‚îú‚îÄ‚îÄ README-app.md         # Documentaci√≥n de la app
‚îú‚îÄ‚îÄ requirements.txt      # Dependencias
‚îú‚îÄ‚îÄ persons/              # Dataset Supervisely
‚îú‚îÄ‚îÄ checkpoints/          # Modelos guardados
‚îÇ   ‚îú‚îÄ‚îÄ best_model.pth   # Mejor modelo
‚îÇ   ‚îî‚îÄ‚îÄ YYYYMMDD_HHMMSS/ # Checkpoints con timestamp
‚îú‚îÄ‚îÄ plots/               # Gr√°ficas de entrenamiento
‚îÇ   ‚îî‚îÄ‚îÄ YYYYMMDD_HHMMSS/ # Plots con timestamp
‚îî‚îÄ‚îÄ logs/               # Logs de entrenamiento
```

## üîß Configuraci√≥n

### Par√°metros de Entrenamiento (main.py)

```python
config = {
    'batch_size': 4,
    'learning_rate': 5e-5,
    'weight_decay': 1e-6,
    'num_epochs': 100,
    'image_size': 384,
    'device': 'cuda' if torch.cuda.is_available() else 'cpu'
}
```

### Funciones de P√©rdida

- **BCE Loss** (Œ±=1.0): Clasificaci√≥n binaria del canal alpha
- **Dice Loss** (Œ≤=1.0): Similitud entre m√°scaras
- **Perceptual Loss** (Œ≥=0.5): Calidad visual de canales RGB
- **Edge Loss** (Œ¥=0.3): Preservaci√≥n de contornos

## üìä Resultados Esperados

### M√©tricas Objetivo
- **IoU**: > 0.85 en validaci√≥n
- **Dice Coefficient**: > 0.90 en validaci√≥n
- **Pixel Accuracy**: > 0.95 en validaci√≥n

### Rendimiento
- **Entrenamiento**: 100 √©pocas en ~4-6 horas (RTX 3080)
- **Inferencia**: ~50ms por imagen (256x256) en GPU
- **Convergencia**: T√≠picamente en 50-70 √©pocas

## üõ†Ô∏è Caracter√≠sticas T√©cnicas

### Procesamiento de Im√°genes
- **Redimensionamiento Inteligente**: Mantiene proporciones con padding
- **Restauraci√≥n Exacta**: Regresa al tama√±o original sin p√©rdida
- **Aumentaci√≥n de Datos**: Flip, rotaci√≥n, cambios de brillo/contraste

### Arquitectura Avanzada
- **Attention Mechanisms**: Focalizaci√≥n autom√°tica en personas
- **Skip Connections**: Preservaci√≥n de detalles de alta resoluci√≥n
- **Gradient Clipping**: Estabilizaci√≥n del entrenamiento
- **Cosine Annealing**: Scheduler de learning rate optimizado

## üîç Uso del Modelo

### Entrenamiento

```python
# El sistema autom√°ticamente:
# 1. Carga y procesa el dataset Supervisely
# 2. Aplica aumentaci√≥n de datos
# 3. Entrena con validaci√≥n cruzada
# 4. Guarda el mejor modelo y checkpoints
# 5. Genera gr√°ficas de progreso

# Ejecutar:
python run_training.py
```

### Inferencia

```python
from main import ModelInference

# Cargar modelo entrenado
inference = ModelInference('checkpoints/best_model.pth')

# Procesar imagen individual
result = inference.remove_background('input.jpg', 'output.png')

# Procesamiento en lote
inference.batch_process('input_dir/', 'output_dir/')
```

## üõ†Ô∏è Soluci√≥n de Problemas

### Error de Memoria GPU
```python
# Reducir batch size en config
config['batch_size'] = 2
```

### Dataset No Encontrado
```bash
# Verificar estructura
ls persons/project/ds1/img/
ls persons/project/ds1/ann/
```

### Problemas de Convergencia
```python
# Ajustar learning rate
config['learning_rate'] = 1e-5
```

## üìö Referencias

- [U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/abs/1505.04597)
- [Attention U-Net: Learning Where to Look](https://arxiv.org/abs/1804.03999)
- [Supervisely Persons Dataset](https://github.com/supervisely-ecosystem/persons)

## ü§ù Contribuciones

Desarrollado como parte de la investigaci√≥n en Computer Vision y Deep Learning en la Maestr√≠a en Inform√°tica de la PUCP.

**Autores:**
- Luis Huacho
- Dominick Alvarez

## üìÑ Licencia

Este proyecto est√° bajo la Licencia MIT para fines acad√©micos y de investigaci√≥n.