# ğŸ¯ U-Net Background Removal System

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-1.12+-orange.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)

Un sistema avanzado de **eliminaciÃ³n de fondos** usando redes U-Net con soporte para mÃºltiples datasets y aplicaciÃ³n web interactiva.

## ğŸŒŸ CaracterÃ­sticas Principales

- **ğŸ§  Arquitectura U-Net Avanzada**: SegmentaciÃ³n precisa de personas
- **ğŸ“Š MÃºltiples Datasets**: Soporte para COCO, Supervisely Persons y datasets personalizados
- **ğŸŒ AplicaciÃ³n Web**: Interfaz Streamlit para uso inmediato
- **âš¡ GPU Optimizado**: Entrenamiento e inferencia acelerados
- **ğŸ“ˆ MÃ©tricas Completas**: IoU, Dice, Pixel Accuracy y anÃ¡lisis de calidad
- **ğŸ”„ Sistema Modular**: FÃ¡cil extensiÃ³n y personalizaciÃ³n
- **ğŸ“± Deployment Ready**: Listo para producciÃ³n con Docker y API

## ğŸš€ Inicio RÃ¡pido

### 1. ConfiguraciÃ³n del Entorno

```bash
# Clonar repositorio
git clone <tu-repositorio>
cd unet-background-removal

# Crear entorno virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# o
venv\Scripts\activate     # Windows

# Instalar dependencias
pip install -r requirements.txt
```

### 2. Preparar Dataset

#### OpciÃ³n A: Dataset COCO (Recomendado)
```bash
# Crear directorio y descargar
mkdir COCO && cd COCO

# Descargar anotaciones y imÃ¡genes
wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip
wget http://images.cocodataset.org/zips/train2017.zip
wget http://images.cocodataset.org/zips/val2017.zip

# Descomprimir
unzip annotations_trainval2017.zip
unzip train2017.zip  
unzip val2017.zip

cd ..
```

#### OpciÃ³n B: Dataset Supervisely Persons
```bash
# Estructura esperada:
persons/
â”œâ”€â”€ project/
â”‚   â”œâ”€â”€ ds1/
â”‚   â”‚   â”œâ”€â”€ img/
â”‚   â”‚   â””â”€â”€ ann/
â”‚   â””â”€â”€ ds2/
â”‚       â”œâ”€â”€ img/
â”‚       â””â”€â”€ ann/
```

### 3. Verificar Sistema

```bash
# VerificaciÃ³n completa (recomendada primera vez)
python main.py verify

# VerificaciÃ³n rÃ¡pida de estructura
python main.py quick

# AnÃ¡lisis del dataset
python main.py analyze
```

### 4. Entrenar Modelo

```bash
# Entrenamiento automÃ¡tico con verificaciÃ³n
python main.py

# O entrenamiento directo
python main.py train
```

### 5. Usar AplicaciÃ³n Web

```bash
# Instalar dependencias adicionales
pip install -r requirements-app.txt

# Ejecutar aplicaciÃ³n
streamlit run app.py
```

## ğŸ“‹ Comandos Disponibles

| Comando | DescripciÃ³n | Tiempo Estimado |
|---------|-------------|-----------------|
| `python main.py` | **Modo automÃ¡tico** - VerificaciÃ³n + entrenamiento | 2-4 horas |
| `python main.py verify` | VerificaciÃ³n completa del sistema | 2-3 minutos |
| `python main.py quick` | VerificaciÃ³n rÃ¡pida de estructura | 30 segundos |
| `python main.py analyze` | AnÃ¡lisis estadÃ­stico del dataset | 1-2 minutos |
| `python main.py train` | Entrenamiento directo | 2-4 horas |
| `python main.py demo` | Demo de inferencia | 1 minuto |
| `streamlit run app.py` | AplicaciÃ³n web interactiva | Inmediato |

## âš™ï¸ ConfiguraciÃ³n del Sistema

### ConfiguraciÃ³n de Entrenamiento (main.py)

```python
config = {
    'batch_size': 16,           # Ajustar segÃºn GPU (8 para â‰¤6GB VRAM)
    'learning_rate': 1e-4,      # Learning rate conservador
    'num_epochs': 100,          # Ã‰pocas de entrenamiento
    'image_size': 384,          # ResoluciÃ³n de procesamiento
    'weight_decay': 1e-6,       # RegularizaciÃ³n
    'num_workers': 8,           # Procesos paralelos
    'device': 'auto',           # auto, cuda, cpu
}
```

### OptimizaciÃ³n por Hardware

```python
# GPU con poca memoria (â‰¤6GB VRAM)
config.update({
    'batch_size': 8,
    'image_size': 256,
    'num_workers': 4
})

# GPU potente (â‰¥12GB VRAM)
config.update({
    'batch_size': 32,
    'image_size': 512,
    'num_workers': 12
})

# Solo CPU (no recomendado)
config.update({
    'batch_size': 4,
    'image_size': 256,
    'device': 'cpu'
})
```

## ğŸ“Š Arquitectura del Sistema

### Componentes Principales

```
unet-background-removal/
â”œâ”€â”€ main.py                 # Punto de entrada principal
â”œâ”€â”€ app.py                  # AplicaciÃ³n web Streamlit
â”œâ”€â”€ models/                 # Arquitecturas de redes
â”‚   â”œâ”€â”€ unet.py            # Modelo U-Net base
â”‚   â””â”€â”€ advanced_unet.py   # Variantes avanzadas
â”œâ”€â”€ datasets/               # Cargadores de datos
â”‚   â”œâ”€â”€ coco_dataset.py    # Dataset COCO
â”‚   â””â”€â”€ supervisely.py     # Dataset Supervisely
â”œâ”€â”€ training/               # LÃ³gica de entrenamiento
â”œâ”€â”€ inference.py            # Sistema de inferencia
â”œâ”€â”€ utils.py               # Utilidades y verificaciones
â”œâ”€â”€ settings.py            # Configuraciones globales
â””â”€â”€ checkpoints/           # Modelos entrenados
```

### Flujo de Datos

```mermaid
graph TD
    A[Dataset] --> B[Preprocessing]
    B --> C[U-Net Model]
    C --> D[Loss Calculation]
    D --> E[Optimization]
    E --> F[Validation]
    F --> G[Best Model Save]
    G --> H[Inference/App]
```

## ğŸ¯ Usando la AplicaciÃ³n Web

### Funcionalidades

- **ğŸ“¤ Carga de ImÃ¡genes**: Drag & drop o selecciÃ³n manual
- **âš™ï¸ ConfiguraciÃ³n**: Ajuste de tamaÃ±o de procesamiento
- **ğŸ‘ï¸ Modo Debug**: VisualizaciÃ³n paso a paso del proceso
- **ğŸ“Š AnÃ¡lisis de Calidad**: MÃ©tricas automÃ¡ticas del resultado
- **ğŸ’¾ Descarga**: Resultado en PNG con transparencia
- **ğŸ“ˆ EstadÃ­sticas**: Cobertura, contraste y definiciÃ³n

### MÃ©tricas de Calidad

La aplicaciÃ³n proporciona anÃ¡lisis automÃ¡tico:

- **Cobertura de Persona**: % del Ã¡rea detectada
- **Contraste de MÃ¡scara**: DefiniciÃ³n de los bordes
- **Calidad de SegmentaciÃ³n**: Score global (0-100)
- **Recomendaciones**: Consejos para mejorar resultados

## ğŸ”§ SoluciÃ³n de Problemas

### Errores Comunes

#### "Dataset no encontrado"
```bash
# Verificar estructura
python main.py quick

# Para COCO:
ls COCO/annotations/person_keypoints_train2017.json
ls COCO/train2017/ | wc -l

# Para Supervisely:
ls persons/project/ds1/img/ | wc -l
```

#### "CUDA out of memory"
```python
# Reducir batch_size en main.py
config['batch_size'] = 8  # o 4

# Reducir tamaÃ±o de imagen
config['image_size'] = 256
```

#### "Modelo no converge"
```python
# Ajustar learning rate
config['learning_rate'] = 5e-5

# Aumentar Ã©pocas
config['num_epochs'] = 200

# Verificar datos
python main.py analyze
```

#### "AplicaciÃ³n web lenta"
```bash
# Verificar modelo existe
ls checkpoints/best_model.pth

# Optimizar configuraciÃ³n CPU
# En app.py, ajustar tamaÃ±o de procesamiento
processing_size = 256  # En lugar de 384
```

### Monitoreo del Entrenamiento

```bash
# Usar screen para sesiones largas
screen -S training
python main.py train
# Ctrl+A, D para detach

# Reconectar mÃ¡s tarde
screen -r training

# Ver progreso en logs
tail -f logs/training_*.log

# Monitorear GPU
watch -n 2 nvidia-smi
```

## ğŸ“ˆ Rendimiento y Benchmarks

### MÃ©tricas Objetivo

| MÃ©trica | Valor Objetivo | Valor TÃ­pico |
|---------|----------------|--------------|
| **IoU** | â‰¥0.85 | 0.82-0.88 |
| **Dice Score** | â‰¥0.90 | 0.87-0.92 |
| **Pixel Accuracy** | â‰¥0.95 | 0.93-0.97 |
| **Inference Time** | <100ms | 50-80ms |

### Rendimiento por Hardware

| Hardware | Tiempo/Imagen | Batch Size | Memoria |
|----------|---------------|------------|---------|
| **RTX 4090** | ~20ms | 32 | 12GB |
| **RTX 3080** | ~35ms | 24 | 10GB |
| **GTX 1080** | ~80ms | 16 | 8GB |
| **CPU (i7)** | ~2000ms | 4 | 8GB |

## ğŸŒ Deployment y ProducciÃ³n

### Docker

```dockerfile
FROM python:3.9-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .
EXPOSE 8501

CMD ["streamlit", "run", "app.py", "--server.address=0.0.0.0"]
```

```bash
# Construir y ejecutar
docker build -t bg-removal .
docker run -p 8501:8501 bg-removal
```

### API REST

```python
# Crear API con FastAPI (ver examples.py)
from fastapi import FastAPI, File, UploadFile

app = FastAPI()

@app.post("/remove_background")
async def remove_background(file: UploadFile = File(...)):
    # Procesar imagen y devolver resultado
    pass
```

### OptimizaciÃ³n para ProducciÃ³n

```python
# Optimizar modelo para inferencia
import torch

# Exportar a TorchScript
model = torch.jit.script(trained_model)
model.save("optimized_model.pt")

# O exportar a ONNX
torch.onnx.export(model, dummy_input, "model.onnx")
```

## ğŸ“š Recursos y Referencias

### DocumentaciÃ³n Adicional

- ğŸ“– **[README.COCO.md](README.COCO.md)**: GuÃ­a especÃ­fica para dataset COCO
- ğŸ­ **[README-app.md](README-app.md)**: DocumentaciÃ³n de la aplicaciÃ³n web
- ğŸ”§ **[Docs/Utils.md](Docs/Utils.md)**: Herramientas y utilidades avanzadas

### Papers de Referencia

- [U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/abs/1505.04597)
- [Attention U-Net: Learning Where to Look](https://arxiv.org/abs/1804.03999)
- [COCO: Common Objects in Context](https://arxiv.org/abs/1405.0312)

### Datasets

- ğŸ·ï¸ **COCO Dataset**: [cocodataset.org](https://cocodataset.org/)
- ğŸ‘¥ **Supervisely Persons**: [app.supervisely.com](https://app.supervisely.com/)

## ğŸ¤ Contribuciones y Desarrollo

### Autores

**Luis Huacho y Dominick Alvarez**  
MaestrÃ­a en InformÃ¡tica - PUCP  

### Estructura del Proyecto

El proyecto estÃ¡ diseÃ±ado con arquitectura modular:

- **SeparaciÃ³n de responsabilidades**: Cada mÃ³dulo tiene un propÃ³sito especÃ­fico
- **ConfiguraciÃ³n centralizada**: Todas las configuraciones en `settings.py`
- **Extensibilidad**: FÃ¡cil agregar nuevos datasets y modelos
- **Testing**: Verificaciones automÃ¡ticas integradas
- **DocumentaciÃ³n**: README especÃ­fico para cada componente

### Contribuir

1. Fork el repositorio
2. Crear rama feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit cambios (`git commit -am 'Agregar nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Crear Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la **Licencia MIT** para fines acadÃ©micos y de investigaciÃ³n.

---

## ğŸ TL;DR - GuÃ­a Ultra RÃ¡pida

```bash
# 1. Setup
git clone <repo> && cd unet-background-removal
python -m venv venv && source venv/bin/activate
pip install -r requirements.txt

# 2. Dataset (COCO recomendado)
mkdir COCO && cd COCO
wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip
wget http://images.cocodataset.org/zips/train2017.zip
unzip *.zip && cd ..

# 3. Verificar y entrenar
python main.py verify
python main.py train

# 4. Usar app web
pip install -r requirements-app.txt
streamlit run app.py
```

**Â¿Problemas?** â†’ `python main.py quick` para verificaciÃ³n rÃ¡pida

**Â¿Primera vez?** â†’ Consulta [README.COCO.md](README.COCO.md) para guÃ­a detallada

**Â¿ProducciÃ³n?** â†’ Ver secciÃ³n Deployment o consultar [README-app.md](README-app.md)
