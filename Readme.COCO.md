# U-Net Autoencoder para RemociÃ³n de Fondo - VersiÃ³n COCO

Un modelo de deep learning que utiliza arquitectura U-Net con Attention Gates para remover automÃ¡ticamente el fondo de imÃ¡genes, manteniendo Ãºnicamente las personas detectadas. **VersiÃ³n adaptada para dataset COCO**.

**Desarrollado por:** Luis Huacho y Dominick Alvarez  
**InstituciÃ³n:** MaestrÃ­a en InformÃ¡tica, PUCP  
**Dataset:** COCO 2017 - Person Keypoints

## ğŸ¯ CaracterÃ­sticas Principales

- **Arquitectura HÃ­brida**: U-Net con Autoencoder para segmentaciÃ³n y reconstrucciÃ³n
- **Dataset COCO**: Entrenado con COCO 2017 Person Keypoints (118K+ imÃ¡genes)
- **Attention Gates**: Enfoque automÃ¡tico en regiones de personas
- **Transfer Learning**: ResNet34 pre-entrenado como backbone
- **SegmentaciÃ³n Avanzada**: Usa anotaciones de segmentaciÃ³n COCO cuando estÃ¡n disponibles
- **PreservaciÃ³n de Dimensiones**: Mantiene el tamaÃ±o original de la imagen

## ğŸ“‹ Requisitos del Sistema

### Software Requerido
```bash
Python >= 3.8
CUDA >= 11.0 (opcional, para GPU)
```

### Dependencias Python
```bash
torch>=1.9.0
torchvision>=0.10.0
opencv-python>=4.5.0
albumentations>=1.0.0
numpy>=1.21.0
matplotlib>=3.4.0
streamlit>=1.25.0
scikit-learn>=0.24.0
Pillow>=8.3.0
```

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### 1. Clonar Repositorio

```bash
git clone <repository-url>
cd unet-background-removal
```

### 2. Crear Entorno Virtual

```bash
# Crear entorno virtual
python -m venv venv

# Activar entorno (Linux/Mac)
source venv/bin/activate

# Activar entorno (Windows)
venv\Scripts\activate
```

### 3. Instalar Dependencias

```bash
# Instalar dependencias bÃ¡sicas
pip install -r requirements.txt

# O instalar manualmente
pip install torch torchvision opencv-python albumentations numpy matplotlib streamlit scikit-learn Pillow
```

### 4. Preparar Dataset COCO

#### OpciÃ³n A: Descarga AutomÃ¡tica (Recomendado)

```bash
# Crear directorio COCO
mkdir COCO
cd COCO

# Descargar anotaciones (253 MB)
wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip
unzip annotations_trainval2017.zip

# Descargar imÃ¡genes de entrenamiento (18 GB)
wget http://images.cocodataset.org/zips/train2017.zip
unzip train2017.zip

# Descargar imÃ¡genes de validaciÃ³n (778 MB)
wget http://images.cocodataset.org/zips/val2017.zip
unzip val2017.zip

cd ..
```

#### OpciÃ³n B: Si ya tienes los archivos

```bash
# AsegÃºrate de que la estructura sea:
COCO/
â”œâ”€â”€ annotations/
â”‚   â”œâ”€â”€ person_keypoints_train2017.json
â”‚   â””â”€â”€ person_keypoints_val2017.json
â”œâ”€â”€ train2017/
â”‚   â””â”€â”€ *.jpg (118,287 archivos)
â””â”€â”€ val2017/
    â””â”€â”€ *.jpg (5,000 archivos)
```

### 5. Verificar InstalaciÃ³n

```bash
# VerificaciÃ³n rÃ¡pida de estructura
python main.py quick

# VerificaciÃ³n completa del sistema
python main.py verify

# AnÃ¡lisis detallado del dataset
python main.py analyze
```

## ğŸ¯ Uso del Sistema

### Comandos Disponibles

| Comando | DescripciÃ³n | Tiempo |
|---------|-------------|--------|
| `python main.py` | **Modo automÃ¡tico** - VerificaciÃ³n + entrenamiento | 2-4 horas |
| `python main.py verify` | VerificaciÃ³n completa del sistema | 2-3 minutos |
| `python main.py quick` | VerificaciÃ³n rÃ¡pida de estructura COCO | 30 segundos |
| `python main.py analyze` | AnÃ¡lisis estadÃ­stico del dataset | 1-2 minutos |
| `python main.py batch` | Prueba de carga de datos | 30 segundos |
| `python main.py train` | Entrenamiento directo (sin verificaciÃ³n) | 2-4 horas |

### Flujo de Trabajo Recomendado

#### 1. Primera Vez - VerificaciÃ³n Completa
```bash
# Verificar todo el sistema
python main.py verify

# Si todo estÃ¡ bien, continuar con entrenamiento
python main.py train
```

#### 2. VerificaciÃ³n RÃ¡pida
```bash
# Solo verificar estructura de archivos
python main.py quick
```

#### 3. AnÃ¡lisis del Dataset
```bash
# Ver estadÃ­sticas detalladas
python main.py analyze
```

**Salida esperada:**
```
ğŸ“ˆ EstadÃ­sticas generales:
   - Total de imÃ¡genes: 64,115
   - Total de anotaciones: 262,465
   - Anotaciones de personas vÃ¡lidas: 149,813
   - ImÃ¡genes con personas vÃ¡lidas: 45,174
   - Promedio de personas por imagen: 3.32
```

#### 4. Entrenamiento AutomÃ¡tico (Recomendado)
```bash
# VerificaciÃ³n + entrenamiento con confirmaciÃ³n
python main.py
```

#### 5. Solo Entrenamiento
```bash
# Saltar verificaciones e ir directo al entrenamiento
python main.py train
```

## âš™ï¸ ConfiguraciÃ³n del Entrenamiento

### ParÃ¡metros por Defecto (main.py)

```python
config = {
    'batch_size': 16,           # Reducido para COCO (imÃ¡genes mÃ¡s variadas)
    'learning_rate': 1e-4,      # Learning rate conservador
    'weight_decay': 1e-6,       # RegularizaciÃ³n ligera
    'num_epochs': 100,          # Ã‰pocas de entrenamiento
    'image_size': 384,          # TamaÃ±o de procesamiento
    'num_workers': 8,           # Trabajadores para carga de datos
    'pin_memory': True,         # OptimizaciÃ³n de memoria
}
```

### Personalizar ConfiguraciÃ³n

```python
# Para GPUs con poca memoria (â‰¤6GB VRAM)
config['batch_size'] = 8
config['image_size'] = 256

# Para entrenamiento rÃ¡pido
config['num_epochs'] = 50
config['learning_rate'] = 2e-4

# Para mÃ¡xima calidad
config['batch_size'] = 32
config['image_size'] = 512
config['num_epochs'] = 200
```

## ğŸ“Š Proceso de Entrenamiento

### Etapas del Entrenamiento

1. **Carga del Dataset** (2-3 minutos)
   - Lectura de anotaciones COCO
   - Filtrado de personas vÃ¡lidas
   - CreaciÃ³n de dataloaders

2. **InicializaciÃ³n** (30 segundos)
   - Carga del modelo U-Net
   - ConfiguraciÃ³n de optimizador
   - PreparaciÃ³n de funciones de pÃ©rdida

3. **Entrenamiento** (2-4 horas)
   - 100 Ã©pocas por defecto
   - ValidaciÃ³n cada Ã©poca
   - Guardado automÃ¡tico del mejor modelo

4. **FinalizaciÃ³n**
   - GeneraciÃ³n de grÃ¡ficas
   - Guardado de checkpoints
   - Resumen de mÃ©tricas

### MÃ©tricas de EvaluaciÃ³n

| MÃ©trica | Objetivo | DescripciÃ³n |
|---------|----------|-------------|
| **IoU** | > 0.85 | Intersection over Union |
| **Dice** | > 0.90 | Coeficiente de Dice |
| **Pixel Accuracy** | > 0.95 | PrecisiÃ³n a nivel de pÃ­xel |
| **Loss** | < 0.1 | PÃ©rdida compuesta |

### Monitoreo del Entrenamiento

```bash
# Ver logs en tiempo real
tail -f logs/training_YYYYMMDD_HHMMSS.log

# Ver progreso en archivos
ls -la checkpoints/
ls -la plots/
```

## ğŸ”§ SoluciÃ³n de Problemas

### Problemas Comunes y Soluciones

#### âŒ "Directorio COCO no encontrado"
```bash
# Verificar estructura
ls -la COCO/
ls -la COCO/annotations/
ls -la COCO/train2017/ | head
ls -la COCO/val2017/ | head

# Si falta, descargar dataset
python main.py quick  # Te mostrarÃ¡ quÃ© falta
```

#### âŒ "CUDA out of memory"
```python
# Reducir batch size en main.py lÃ­nea ~XXX
config['batch_size'] = 8  # En lugar de 16
config['image_size'] = 256  # En lugar de 384
```

#### âŒ "Dataset vacÃ­o"
```bash
# Verificar anotaciones
python main.py analyze

# DeberÃ­a mostrar:
# - Anotaciones de personas vÃ¡lidas: 149,813
# - ImÃ¡genes con personas vÃ¡lidas: 45,174
```

#### âŒ "Error cargando batch"
```bash
# Probar carga individual
python main.py batch

# Reducir workers si hay problemas
config['num_workers'] = 0  # En main.py
```

#### âŒ "Entrenamiento muy lento"
```bash
# Verificar que usa GPU
nvidia-smi  # DeberÃ­a mostrar uso de GPU

# Si usa CPU, verificar instalaciÃ³n CUDA
python -c "import torch; print(torch.cuda.is_available())"
```

### Comandos de DiagnÃ³stico

```bash
# VerificaciÃ³n completa del sistema
python main.py verify

# Ver uso de recursos durante entrenamiento
watch -n 1 nvidia-smi  # Para GPU
watch -n 1 'free -h && df -h'  # Para RAM y disco

# Verificar logs de errores
tail -f logs/training_*.log | grep ERROR

# Limpiar memoria si es necesario
python -c "import torch; torch.cuda.empty_cache()"
```

## ğŸ“ Estructura de Archivos Generados

```
unet-background-removal/
â”œâ”€â”€ COCO/                     # Dataset COCO (19+ GB)
â”‚   â”œâ”€â”€ annotations/
â”‚   â”œâ”€â”€ train2017/
â”‚   â””â”€â”€ val2017/
â”œâ”€â”€ checkpoints/              # Modelos entrenados
â”‚   â”œâ”€â”€ best_model.pth       # Mejor modelo (principal)
â”‚   â”œâ”€â”€ last_model.pth       # Ãšltimo checkpoint
â”‚   â””â”€â”€ YYYYMMDD_HHMMSS/     # Checkpoints con timestamp
â”œâ”€â”€ plots/                   # GrÃ¡ficas de entrenamiento
â”‚   â”œâ”€â”€ training_history.png
â”‚   â””â”€â”€ YYYYMMDD_HHMMSS/     # Plots con timestamp
â”œâ”€â”€ logs/                    # Logs de entrenamiento
â”‚   â””â”€â”€ training_*.log
â”œâ”€â”€ main.py                  # CÃ³digo principal (ADAPTADO PARA COCO)
â”œâ”€â”€ app.py                   # AplicaciÃ³n Streamlit
â”œâ”€â”€ run_training.py          # Script automatizado
â””â”€â”€ README.COCO.md          # Esta documentaciÃ³n
```

## ğŸš€ DespuÃ©s del Entrenamiento

### 1. Verificar Resultados

```bash
# Verificar que el modelo se guardÃ³
ls -la checkpoints/best_model.pth

# Ver grÃ¡ficas de entrenamiento
ls -la plots/training_history.png
```

### 2. Usar el Modelo Entrenado

#### AplicaciÃ³n Web (Recomendado)
```bash
# Ejecutar interfaz Streamlit
streamlit run app.py

# Abrir en navegador: http://localhost:8501
```

#### Inferencia por CÃ³digo
```python
from main import ModelInference

# Cargar modelo
inference = ModelInference('checkpoints/best_model.pth')

# Procesar imagen individual
result = inference.remove_background('input.jpg', 'output.png')

# Procesamiento en lote
inference.batch_process('input_dir/', 'output_dir/')
```

#### Script de Entrenamiento Automatizado
```bash
# Usar script con logs organizados
python run_training.py

# Con logs en tiempo real
python run_training.py --verbose
```

### 3. Evaluar Calidad

| MÃ©trica | Valor Esperado | Significado |
|---------|----------------|-------------|
| **Train IoU** | > 0.85 | Modelo aprende correctamente |
| **Val IoU** | > 0.80 | Buena generalizaciÃ³n |
| **Diferencia Train-Val** | < 0.10 | Sin overfitting |
| **Convergencia** | 50-70 Ã©pocas | Entrenamiento eficiente |

## ğŸ“Š Diferencias vs Dataset Supervisely

| Aspecto | Supervisely (Original) | COCO (Esta VersiÃ³n) |
|---------|----------------------|-------------------|
| **ImÃ¡genes de Entrenamiento** | ~8,000 | ~45,000 |
| **Calidad de Anotaciones** | Muy alta | Alta |
| **Variedad de Poses** | Media | Muy alta |
| **Variedad de Fondos** | Media | Muy alta |
| **TamaÃ±o de Dataset** | 2-3 GB | 19+ GB |
| **Tiempo de Entrenamiento** | 2-3 horas | 3-5 horas |
| **Calidad Esperada** | Excelente | Muy buena |

## ğŸ¯ Optimizaciones para COCO

### ConfiguraciÃ³n para Diferentes Escenarios

#### ğŸš€ Entrenamiento RÃ¡pido (Prototipo)
```python
config = {
    'batch_size': 32,
    'learning_rate': 2e-4,
    'num_epochs': 30,
    'image_size': 256,
}
# Tiempo: ~45 minutos en GPU
```

#### âš–ï¸ Entrenamiento Balanceado (Recomendado)
```python
config = {
    'batch_size': 16,
    'learning_rate': 1e-4,
    'num_epochs': 100,
    'image_size': 384,
}
# Tiempo: ~3 horas en GPU
```

#### ğŸ¯ MÃ¡xima Calidad (ProducciÃ³n)
```python
config = {
    'batch_size': 8,
    'learning_rate': 5e-5,
    'num_epochs': 200,
    'image_size': 512,
}
# Tiempo: ~8 horas en GPU
```

## ğŸ” ValidaciÃ³n y Testing

### Scripts de ValidaciÃ³n

```bash
# ValidaciÃ³n completa antes de entrenar
python main.py verify

# Verificar solo estructura COCO
python main.py quick

# AnÃ¡lisis estadÃ­stico del dataset
python main.py analyze

# Probar carga de un batch
python main.py batch
```

### Verificaciones AutomÃ¡ticas

El sistema incluye verificaciones automÃ¡ticas para:

- âœ… Estructura de directorios COCO
- âœ… Presencia de archivos de anotaciones
- âœ… Integridad de imÃ¡genes
- âœ… Forward pass del modelo
- âœ… Carga de datos sin errores
- âœ… Compatibilidad GPU/CPU

## ğŸ’¡ Consejos y Mejores PrÃ¡cticas

### Para Mejor Rendimiento

1. **SSD**: Usa SSD para almacenar COCO (mejora velocidad de carga)
2. **RAM**: 16+ GB recomendado para batch_size > 16
3. **GPU**: NVIDIA con 8+ GB VRAM para mÃ¡xima velocidad
4. **Monitoring**: Usa `watch nvidia-smi` durante entrenamiento

### Para Mejor Calidad

1. **Ã‰pocas**: MÃ­nimo 100 Ã©pocas para convergencia
2. **Learning Rate**: Usar 1e-4 o menos para estabilidad
3. **Image Size**: 384+ pÃ­xeles para mejor detalle
4. **Patience**: Esperar convergencia completa

### Para Desarrollo

1. **VerificaciÃ³n**: Siempre usar `python main.py verify` primero
2. **Logs**: Monitorear logs para detectar problemas temprano
3. **Checkpoints**: El mejor modelo se guarda automÃ¡ticamente
4. **Resumir**: Puedes resumir entrenamiento desde `last_model.pth`

## ğŸ“ Soporte y Contacto

### Problemas Frecuentes

- **Dataset no encontrado**: Verificar estructura con `python main.py quick`
- **Memoria insuficiente**: Reducir `batch_size` y/o `image_size`
- **Entrenamiento lento**: Verificar uso de GPU con `nvidia-smi`
- **Calidad baja**: Aumentar Ã©pocas y/o tamaÃ±o de imagen

### Recursos Adicionales

- ğŸ“– **DocumentaciÃ³n Original**: `README.md`
- ğŸ­ **AplicaciÃ³n Web**: `README-app.md`
- ğŸ”§ **CÃ³digo Principal**: `main.py` (adaptado para COCO)
- ğŸ“Š **Dataset COCO**: [cocodataset.org](https://cocodataset.org/)

### Desarrolladores

**Luis Huacho y Dominick Alvarez**  
MaestrÃ­a en InformÃ¡tica - PUCP  
EspecializaciÃ³n en Computer Vision y Deep Learning

---

## ğŸ Inicio RÃ¡pido - 5 Pasos

```bash
# 1. Clonar y preparar entorno
git clone <repo> && cd unet-background-removal
python -m venv venv && source venv/bin/activate
pip install torch torchvision opencv-python albumentations numpy matplotlib streamlit

# 2. Descargar COCO (si no lo tienes)
mkdir COCO && cd COCO
wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip
wget http://images.cocodataset.org/zips/train2017.zip
wget http://images.cocodataset.org/zips/val2017.zip
unzip annotations_trainval2017.zip && unzip train2017.zip && unzip val2017.zip
cd ..

# 3. Verificar todo
python main.py verify

# 4. Entrenar modelo
python main.py train

# 5. Usar aplicaciÃ³n web
streamlit run app.py
```

Â¡El sistema estÃ¡ listo para funcionar con tu dataset COCO! ğŸš€